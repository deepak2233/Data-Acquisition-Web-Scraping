{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Web Scraping?\n",
    "Web scraping is an automated method used to extract large amounts of data from websites. The data on the websites are unstructured. Web scraping helps collect these unstructured data and store it in a structured form. There are different ways to scrape websites such as online Services, APIs or writing your own code. In this article, we’ll see how to implement web scraping with python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why is Web Scraping Used?\n",
    "Web scraping is used to collect large information from websites. But why does someone have to collect such large data from websites? To know about this, let’s look at the applications of web scraping:\n",
    "\n",
    "- <b>Price Comparison:</b> Services such as ParseHub use web scraping to collect data from online shopping websites and use it to compare the prices of products.\n",
    "- <b>Email address gathering:</b> Many companies that use email as a medium for marketing, use web scraping to collect email ID and then send bulk emails.\n",
    "- <b>Social Media Scraping:</b> Web scraping is used to collect data from Social Media websites such as Twitter to find out what’s trending.\n",
    "- <b>Research and Development:</b> Web scraping is used to collect a large set of data (Statistics, General Information, Temperature, etc.) from websites, which are analyzed and used to carry out Surveys or for R&D.\n",
    "- <b>Job listings:</b> Details regarding job openings, interviews are collected from different websites and then listed in one place so that it is easily accessible to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Crawling v/s Web Scraping\n",
    "The terms Web Crawling and Scraping are often used interchangeably as the basic concept of them is to extract data. However, they are different from each other. We can understand the basic difference from their definitions.\n",
    "\n",
    "Web crawling is basically used to index the information on the page using bots aka crawlers. It is also called indexing. On the hand, web scraping is an automated way of extracting the information using bots aka scrapers. It is also called data extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs: An Alternative to Web Scraping\n",
    "Some website providers offer Application Programming Interfaces (APIs) that allow you to access their data in a predefined manner. With APIs, you can avoid parsing HTML and instead access the data directly using formats like JSON and XML. HTML is primarily a way to visually present content to users.\n",
    "\n",
    "When you use an API, the process is generally more stable than gathering the data through web scraping. That’s because APIs are made to be consumed by programs, rather than by human eyes. If the design of a website changes, then it doesn’t mean that the structure of the API has changed.\n",
    "\n",
    "However, APIs can change as well. Both the challenges of variety and durability apply to APIs just as they do to websites. Additionally, it’s much harder to inspect the structure of an API by yourself if the provided documentation is lacking in quality.\n",
    "\n",
    "The approach and tools you need to gather information using APIs are outside the scope of this tutorial. To learn more about it, check out API Integration in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scraping using Beautiful Soup\n",
    "- Import Beautiful Soup, For Installation <b> pip install bs4</b>\n",
    "- Make a Get request to fetch page Data\n",
    "- Parse HTML\n",
    "- Filter Relvant Parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 : To scrape the andriod version history wikipedia website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_url = \"https://en.wikipedia.org/wiki/Android_version_history\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Get request to fetch page Data\n",
    "android_data = urlopen(android_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n"
     ]
    }
   ],
   "source": [
    "print(type(android_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the website in HTML form\n",
    "android_html = android_data.read()\n",
    "#print(android_html)\n",
    "android_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the website using BeautifulSoup tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Parse the HTML page, To Parse the website we have to used Beautiful soup \n",
    "# tool, To install that we have to import :\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_soup = soup(android_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(android_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print(type(android_soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">Android version history</h1>]\n"
     ]
    }
   ],
   "source": [
    "# To find the heading tage we can use .h1 menully or findAll('tag') function \n",
    "print(android_soup.findAll('h1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the heading tage we can use .h1 menully or findAll('tag') function \n",
    "# print(android_soup.findAll('h2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the heading tage we can use .h1 menully or findAll('[]')\n",
    "# function it will return all tags that present in list list\n",
    "# print(android_soup.findAll(['h1','h2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the table \n",
    "tables = android_soup.findAll('table', {'class':'wikitable'})\n",
    "# print(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_table = tables[0]\n",
    "#print(android_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Useful Information\n",
    "- Remove undesired tags\n",
    "- Extract table header & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Extract Table  Header\n",
    "header = android_table.findAll('th')\n",
    "print(len(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(header[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name', 'Version number(s)', 'Initial stablerelease date', 'Supported (security fixes)', 'API level', 'References']\n"
     ]
    }
   ],
   "source": [
    "# Now whole Header we will use loop\n",
    "column_title = [ct.text[:-1] for ct in header]\n",
    "print(column_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Extract Row Data \n",
    "row_data = android_table.findAll('tr')\n",
    "# print(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "No official codename\n",
      "1.0\n",
      "September 23, 2008\n",
      "No\n",
      "1\n",
      "[9]\n"
     ]
    }
   ],
   "source": [
    "# Now Extract Row Data \n",
    "row_data = android_table.findAll('tr')[1:]\n",
    "print(len(row_data))\n",
    "first_row = row_data[0].findAll('td',{})\n",
    "for d in first_row:\n",
    "    print(d.text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "February 9, 2009\n",
      "No\n",
      "2\n",
      "[9][14]\n"
     ]
    }
   ],
   "source": [
    "# Now Extract 2nd Row Data \n",
    "row_data = android_table.findAll('tr')[1:]\n",
    "first_row = row_data[1].findAll('td',{})\n",
    "for d in first_row:\n",
    "    print(d.text[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['No official codename', '1.0', 'September 23, 2008', 'No', '1', '[9]'], ['No official codename', '1.1', 'February 9, 2009', 'No', '2', '[9][14]'], ['Cupcake', '1.5', 'April 27, 2009', 'No', '3', '[15]'], ['Donut', '1.6', 'September 15, 2009', 'No', '4', '[16]'], ['Eclair', '2.0 – 2.1', 'October 26, 2009', 'No', '5 – 7', '[17]'], ['Froyo', '2.2 – 2.2.3', 'May 20, 2010', 'No', '8', '[18]'], ['Gingerbread', '2.3 – 2.3.7', 'December 6, 2010', 'No', '9 – 10', '[19]'], ['Honeycomb', '3.0 – 3.2.6', 'February 22, 2011', 'No', '11 – 13', '[20]'], ['Ice Cream Sandwich', '4.0 – 4.0.4', 'October 18, 2011', 'No', '14 – 15', '[21]'], ['Jelly Bean', '4.1 – 4.3.1', 'July 9, 2012', 'No', '16 – 18', '[22]'], ['KitKat', '4.4 – 4.4.4', 'October 31, 2013', 'No', '19 – 20', '[23]'], ['Lollipop', '5.0 – 5.1.1', 'November 12, 2014', 'No', '21 – 22', '[24]'], ['Marshmallow', '6.0 – 6.0.1', 'October 5, 2015', 'No', '23', '[25]'], ['Nougat', '7.0 – 7.1.2', 'August 22, 2016', 'No', '24 – 25', '[26][27][28][29]'], ['Oreo', '8.0 – 8.1', 'August 21, 2017', 'Yes', '26 – 27', '[30]'], ['Pie', '9', 'August 6, 2018', 'Yes', '28', '[31]'], ['Android 10', '10', 'September 3, 2019', 'Yes', '29', '[32]'], ['Android 11', '11', 'September 8, 2020', 'Yes', '30', '[33]']]\n"
     ]
    }
   ],
   "source": [
    "# Now Extract all the columns corresponding the rows\n",
    "table_rows = []\n",
    "for count, row in enumerate(row_data):\n",
    "    current_row = []\n",
    "    if count == 1:\n",
    "        current_row.append(\"No official codename\")\n",
    "    row_data = row.findAll('td', {})\n",
    "    for idx, data in enumerate(row_data):\n",
    "        current_row.append(data.text[:-1])\n",
    "    table_rows.append(current_row)\n",
    "print(table_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convet the Extracted Data in CSV Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Android_version_history.csv'\n",
    "with open(filename, 'w', encoding = 'utf-8') as f:\n",
    "    # Write the header\n",
    "    header_string = ','.join(column_title)\n",
    "    header_string += '\\n'\n",
    "    f.write(header_string)\n",
    "    \n",
    "    for row in table_rows:\n",
    "        row_string = \"\"\n",
    "        for w in row:\n",
    "            w = w.replace(',','')\n",
    "            row_string += w + ','\n",
    "        row_string = row_string[:-1]\n",
    "        row_string += '\\n'\n",
    "        f.write(row_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cleaning the DataSets\n",
    "- Removing unwanted commas & symbols\n",
    "- undesired information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Android_version_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Version number(s)</th>\n",
       "      <th>Initial stablerelease date</th>\n",
       "      <th>Supported (security fixes)</th>\n",
       "      <th>API level</th>\n",
       "      <th>References</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No official codename</td>\n",
       "      <td>1.0</td>\n",
       "      <td>September 23 2008</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>[9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No official codename</td>\n",
       "      <td>1.1</td>\n",
       "      <td>February 9 2009</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>[9][14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupcake</td>\n",
       "      <td>1.5</td>\n",
       "      <td>April 27 2009</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>[15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donut</td>\n",
       "      <td>1.6</td>\n",
       "      <td>September 15 2009</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eclair</td>\n",
       "      <td>2.0 – 2.1</td>\n",
       "      <td>October 26 2009</td>\n",
       "      <td>No</td>\n",
       "      <td>5 – 7</td>\n",
       "      <td>[17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Froyo</td>\n",
       "      <td>2.2 – 2.2.3</td>\n",
       "      <td>May 20 2010</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>[18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gingerbread</td>\n",
       "      <td>2.3 – 2.3.7</td>\n",
       "      <td>December 6 2010</td>\n",
       "      <td>No</td>\n",
       "      <td>9 – 10</td>\n",
       "      <td>[19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honeycomb</td>\n",
       "      <td>3.0 – 3.2.6</td>\n",
       "      <td>February 22 2011</td>\n",
       "      <td>No</td>\n",
       "      <td>11 – 13</td>\n",
       "      <td>[20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ice Cream Sandwich</td>\n",
       "      <td>4.0 – 4.0.4</td>\n",
       "      <td>October 18 2011</td>\n",
       "      <td>No</td>\n",
       "      <td>14 – 15</td>\n",
       "      <td>[21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jelly Bean</td>\n",
       "      <td>4.1 – 4.3.1</td>\n",
       "      <td>July 9 2012</td>\n",
       "      <td>No</td>\n",
       "      <td>16 – 18</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name Version number(s) Initial stablerelease date  \\\n",
       "0  No official codename               1.0          September 23 2008   \n",
       "1  No official codename               1.1            February 9 2009   \n",
       "2               Cupcake               1.5              April 27 2009   \n",
       "3                 Donut               1.6          September 15 2009   \n",
       "4                Eclair         2.0 – 2.1            October 26 2009   \n",
       "5                 Froyo       2.2 – 2.2.3                May 20 2010   \n",
       "6           Gingerbread       2.3 – 2.3.7            December 6 2010   \n",
       "7             Honeycomb       3.0 – 3.2.6           February 22 2011   \n",
       "8    Ice Cream Sandwich       4.0 – 4.0.4            October 18 2011   \n",
       "9            Jelly Bean       4.1 – 4.3.1                July 9 2012   \n",
       "\n",
       "  Supported (security fixes) API level References  \n",
       "0                         No         1        [9]  \n",
       "1                         No         2    [9][14]  \n",
       "2                         No         3       [15]  \n",
       "3                         No         4       [16]  \n",
       "4                         No     5 – 7       [17]  \n",
       "5                         No         8       [18]  \n",
       "6                         No    9 – 10       [19]  \n",
       "7                         No   11 – 13       [20]  \n",
       "8                         No   14 – 15       [21]  \n",
       "9                         No   16 – 18       [22]  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Accessing the data in Data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 9 2009\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1][2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
